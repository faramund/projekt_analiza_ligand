---
title: "Analiza ligand"
author: "Stanley Hardt"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: 
  html_document: 
    keep_md: yes
    theme: united
    toc: yes
---
1. Wykorzystane biblioteki
---
```{r wykorzystane_biblioteki, warning=FALSE, message=FALSE}
  library(dplyr)
  library(knitr)
  library(ggplot2)
  library(reshape2)
  library(cluster)
  library(caret)
```
2. Powtarzalność raportu
---
```{r powtarzalność_raportu, warning=FALSE, message=FALSE}
  set.seed(23)
```
3. Wczytanie danych
---
```{r wczytanie_danych, warning=FALSE, message=FALSE}

  # Załadowanie tabeli bez wykorzystania utworzonych klas
  dane <- read.table("~/Pobrane/all_summary.txt", skip = 0, header = TRUE, sep = ";")
  
  df<-as.data.frame.matrix(dane) 
```
4. Usuwanie wierszy z okreslonymi wartosciam res_name
---
```{r usuwanie_wierszy, warning=FALSE, message=FALSE }
  df_bez <- filter( df, !(res_name %in% c("DA","DC","DT", "DU", "DG", "DI","UNK", "UNX", "UNL", "PR", "PD", "Y1", "EU", "N", "15P", "UQ", "PX4", "NAN")))%>% 
       filter(!is.na(res_name)) %>%
       filter(!is.nan(res_name))
```
5. Pozostawienie wierszy z unikatowymi wartosciami pdb_code i res_name
---
```{r pozostawienie_unikatowych, warning=FALSE, message=FALSE }  
  df_unique <- distinct(df_bez, pdb_code, res_name)
```
6. Podsumowanie kolumn
---
```{r podsumowanie_kolumn, warning=FALSE, message=FALSE }  
  tabela_summary <- summarise(df_unique,
              pdb_count = n_distinct(pdb_code),
              pdb_min = mean(pdb_code),
              pdb_max = mean(pdb_code),
              pdb_mean = mean(pdb_code),
              res_count = n_distinct(res_name),
              res_min = mean(res_name),
              res_max = mean(res_name),
              res_mean = mean(res_name)  
            )
  kable(tabela_summary)
  
```

7. Korelacja między zmiennymi
---
```{r korelacja, warning=FALSE, message=FALSE }  
  # funkcja układająca macierz wg wartości
  reorder_cormat <- function(cormat){
    dd <- as.dist((1-cormat)/2)
    dd[is.na(dd)] <- 2
    hc <- hclust(dd)
    cormat <-cormat[hc$order, hc$order]
  }
  
  # wybranie kolumn, ktorych korelacja potencjalnie nas moze zainteresowac
  clear_df <- select(df_unique, one_of(c("local_volume", "local_electrons", "local_mean" ,"local_std", "local_max", "local_skewness","local_parts")))
  cor_df <- cor(clear_df, use="complete.obs")
  
  # przeorganizowanie zmiennych wg wartosci korelacji
  cor_df <-reorder_cormat(cor_df)
  
  # wybranie dolnego trojkata
  cor_df[upper.tri(cor_df)]<- NA
  cor_df <- melt(cor_df,  na.rm = TRUE)
  
  wykres_korelacji <- ggplot(cor_df, aes(x =  Var1, y = Var2 , fill=value)) + 
    geom_raster() +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", name="Korelacja") +
    theme_minimal() + 
    theme( 
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank(),
      legend.justification = c(1, 0),
      legend.position = c(0.6, 0.7),
      legend.direction = "horizontal") +
    theme(
      axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) + 
    coord_fixed() +
    guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5)) +
    geom_tile(color = "white")
  
  wykres_korelacji
```

8. Określenie ile przykładów ma każda klasa(res_name)
---
```{r lista_przykladow_res_name, warning=FALSE, message=FALSE }  

  tabela_res <- group_by(df_unique, res_name)
  tabela_res <- summarise(tabela_res, wystapienia = n()) %>%
    arrange(desc(wystapienia))
  
  kable(head(tabela_res,15))  
```

9. Wykres rozkladow liczby atomów i elektronów
---
```{r wykres_rozkladow_atomow_i_elektronow, warning=FALSE, message=FALSE }  
  
  # Wyliczenie rozkladu atomow
  rozklad_atomow <- select(df_unique, local_res_atom_non_h_count) %>%
                    group_by(local_res_atom_non_h_count) %>%
                    summarise(wystapienia=n())
  
  wykres_rozkladow_atomow <- ggplot(rozklad_atomow, 
                                    aes(x = local_res_atom_non_h_count , y = wystapienia)) + 
    geom_bar(stat = "identity", position = "identity", size = 0.2)
  
  wykres_rozkladow_atomow
  
  # Wyliczenie rozkladu elektron
  rozklad_elektronow <- select(df_unique, local_res_atom_non_h_electron_sum) %>%
                    group_by(local_res_atom_non_h_electron_sum) %>%
                    summarise(wystapienia=n())
  
  
  wykres_rozkladu_elektronow <- ggplot(rozklad_elektronow, 
                                    aes(x = local_res_atom_non_h_electron_sum , y = wystapienia)) + 
    geom_bar(stat = "identity", position = "identity", size = 0.2)
  
  wykres_rozkladu_elektronow
  
```

10. Odtworzenie wykresu
---
```{r odtworzenie_wykresu, warning=FALSE, message=FALSE }  
  wykres_rozkladu_atomow_i_elektronow <- ggplot(df_unique, 
                      aes(x = local_res_atom_non_h_electron_sum , y = local_res_atom_non_h_count)) +
    stat_density2d(geom = "tile", aes(fill = ..density..), contour = FALSE ) +
    theme_bw() + 
    scale_fill_gradientn(
      colours =  c( "#6930A9","#72D39D","#F8FFA9","#A10045"), 
      na.value =  "#6930A9") + 
    scale_x_continuous(breaks = seq(100,601,100)) + 
    scale_y_continuous(breaks = seq(20,101,20)) + 
    coord_fixed(ratio = 4.5, xlim = c(0,650), ylim = c(0,100)) +
    theme( 
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          legend.position = "none")
  
  wykres_rozkladu_atomow_i_elektronow <- ggExtra::ggMarginal(wykres_rozkladu_atomow_i_elektronow, type = "histogram", margins = "both", size = 5, col = 'black', fill = 'red', binwidth = 5)
  wykres_rozkladu_atomow_i_elektronow
  
```

11. 10 klas z największą niezgodnością atomów i elektronów
---
```{r tabela_klas_z_najwieksza_niezgodnoscia_atomow_i_elektronow, warning=FALSE, message=FALSE }  
  tabela_niezgodnosci_atomow <- mutate(df_unique, niezgodnosc = abs(local_res_atom_non_h_count - dict_atom_non_h_count)) %>%
    group_by(res_name) %>%
    summarize(count = n(), mean = mean(niezgodnosc)) %>%
    arrange(desc(mean))
  tabela_niezgodnosci_elektronow <- mutate(df_unique, niezgodnosc = abs(local_res_atom_non_h_electron_sum - dict_atom_non_h_electron_sum)) %>%
    group_by(res_name) %>%
    summarize(count = n(), mean = mean(niezgodnosc)) %>%
    arrange(desc(mean))  
  
  kable(head(tabela_niezgodnosci_atomow,10))
```

12. Rozkład wartości kolumn z nazwą zaczynającą się od part_01
---
```{r rozklad_wartosci_kolumn_part_01, warning=FALSE, message=FALSE }  
  kolumny_part <- select(df_unique, starts_with("part_01") )
  for(i in 1:ncol(kolumny_part)){
    wykres_rozkladu <- ggplot(kolumny_part, aes_string(names(kolumny_part)[i])) + geom_histogram()
    print(wykres_rozkladu)  
  }
  
```

13. Przewidywanie liczby atomów i elektronów
---
```{r przewidywanie_atom_elektr, warning=FALSE, message=FALSE }  
  # wyczyszczenie danych poprzez usuniecie wartosci nan i na
  df_clear <- filter( df_unique, !is.na(local_res_atom_non_h_count)) %>%
              filter(!is.na(local_res_atom_non_h_electron_sum)) %>%
              filter(!is.nan(local_res_atom_non_h_count))%>%
              filter(!is.nan(local_res_atom_non_h_electron_sum))
  ##
  # Przewidywanie sumy atomow
  
  # do przewidywania wybieram kolumny, analizowane poprzednio, poniewaz uwazam, ze jest w nich 
  # najwiekszy potencjal eksploracyjny
  df_clear_atom <- select(df_clear, local_res_atom_non_h_count,
                                      part_00_blob_electron_sum:part_00_density_sqrt_E3)
    
  # dziele zbior na treningowy ( 75% danych ) i testowy ( 25% danych)
  inTraining <- 
    createDataPartition(
        # atrybut do stratyfikacji
        y = df_clear_atom$local_res_atom_non_h_count,
        # procent w zbiorze uczącym
        p = .75,
        # chcemy indeksy a nie listę
        list = FALSE)

  training <- df_clear_atom[ inTraining,]
  testing  <- df_clear_atom[-inTraining,]
  
  # ucze model za pomoca regresji liniowej na podstawie zbioru treningowego
  fit <- train(local_res_atom_non_h_count ~ . , data = training, method = "lm")
  fit
  
  # oceniam stworzony model na podstawie zestawu testowego
  predClasses <- predict(fit, newdata = na.omit(testing))
  podsumowanie <-data.frame(obs = na.omit(testing)$local_res_atom_non_h_count, pred=predClasses)
  kable(defaultSummary(podsumowanie))
  
  ##
  # Przewidywanie sumy elektronow
  
  # do przewidywania wybieram kolumny, analizowane poprzednio, poniewaz uwazam, ze jest w nich 
  # najwiekszy potencjal eksploracyjny
  df_clear_electron <- select(df_clear, local_res_atom_non_h_electron_sum, 
                          part_00_blob_electron_sum:part_00_density_sqrt_E3)
    
  # dziele zbior na treningowy ( 75% danych ) i testowy ( 25% danych)
  inTraining <- 
    createDataPartition(
        # atrybut do stratyfikacji
        y = df_clear_electron$local_res_atom_non_h_electron_sum,
        # procent w zbiorze uczącym
        p = .75,
        # chcemy indeksy a nie listę
        list = FALSE)

  training <- df_clear_electron[ inTraining,]
  testing  <- df_clear_electron[-inTraining,]
  
  # ucze model za pomoca regresji liniowej na podstawie zbioru treningowego
  fit <- train(local_res_atom_non_h_electron_sum ~ . , data = training, method = "lm")
  fit
  
  # oceniam stworzony model na podstawie zestawu testowego
  predClasses <- predict(fit, newdata = na.omit(testing))
  
  podsumowanie <-data.frame(obs =  na.omit(testing)$local_res_atom_non_h_electron_sum, pred=predClasses)
  kable(defaultSummary(podsumowanie))
  
```

14. Przewidywanie res_name
---
```{r przewidywanie_res_name, warning=FALSE, message=FALSE }  

  
  # do przewidywania wybieram wiersze z wartościa res_name, ktore powtarzaja sie przynajmniej 15 razy
  # pozwala to na analizowanie jedynie tych przypadkow, dla ktorych mamy duza liczbe danych 
  # wejsciowych
  res_names_to_analyze <- group_by(df_unique, res_name) %>% 
    summarise(count =n()) %>% 
    filter(count>=15)
  
  # tak jak poprzednio wybieramy jedynie kolumny potecjalnie majace najwiekszy wplyw na res_name
  df_clear_res_name <- subset(df_unique, res_name %in% res_names_to_analyze$res_name) %>%
     select(res_name, part_00_blob_electron_sum:part_00_density_sqrt_E3)
  
  # podzial na zbior testowy i treningowy
  inTraining <- 
    createDataPartition(
        # atrybut do stratyfikacji
        y = df_clear_res_name$res_name,
        # procent w zbiorze uczącym
        p = .75,
        # chcemy indeksy a nie listę
        list = FALSE)

  training <- df_clear_res_name[ inTraining,]
  testing  <- df_clear_res_name[-inTraining,]
  
    
  # schemat uczenie za pomoca powtrzonej oceny krzyzowej
  control_model <- trainControl(
    method = "repeatedcv",
    number = 2,
    repeats = 5)
  
  # ucze model za pomoca regresji liniowej na podstawie zbioru treningowego
  fit <-  train(res_name ~ .,
             data = training,
             method = "rf",
             trControl = control_model,
             # Paramter dla algorytmu uczącego
             ntree = 10)
  fit
  # oceniam stworzony model na podstawie zestawu testowego
  predClasses <- predict(fit, newdata = na.omit(testing))
  podsumowanie <-data.frame(obs =  na.omit(testing)$res_name, pred=predClasses)
  kable(defaultSummary(podsumowanie))
  